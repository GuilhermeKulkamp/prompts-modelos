# üìÇ Modelos de Prompts para IA

![License](https://img.shields.io/badge/license-MIT-green.svg)
![Status](https://img.shields.io/badge/status-active-success.svg)
![Language](https://img.shields.io/badge/language-MD%20%7C%20JSON-blue.svg)

Reposit√≥rio para armazenar e versionar **modelos de prompts** reutiliz√°veis para diferentes IAs (ChatGPT, Claude, etc.), em formatos adequados tanto para **leitura humana** (`.md`) quanto para **uso program√°tico** (`.json`).

---

## üéØ Objetivo

Este reposit√≥rio tem como prop√≥sito:

- Centralizar e organizar modelos de prompts.
- Garantir **consist√™ncia** na escrita e formata√ß√£o dos prompts.
- Facilitar **reuso** em scripts, APIs e aplica√ß√µes (Node.js, Next.js, Python, etc.).
- Permitir evolu√ß√£o controlada via **Git/GitHub** (versionamento, PRs, hist√≥rico).

---

## üìÅ Estrutura do Reposit√≥rio

Exemplo de estrutura sugerida:


```bash 
.
‚îú‚îÄ‚îÄ README.md 
‚îú‚îÄ‚îÄ LICENSE 
‚îú‚îÄ‚îÄ mercado-livre/ 
‚îÇ   ‚îú‚îÄ‚îÄ opiniao-mercado-livre.md 
‚îÇ   ‚îî‚îÄ‚îÄ opiniao-mercado-livre.json 
‚îî‚îÄ‚îÄ outros/ 
    ‚îî‚îÄ‚îÄ exemplo-modelo.md
```

Sugest√£o de categorias (pastas):

- `mercado-livre/` ‚Äì prompts espec√≠ficos para avalia√ß√µes, intera√ß√µes e automa√ß√µes envolvendo Mercado Livre.
- `atendimento/` ‚Äì prompts para suporte ao cliente, respostas padr√£o, etc.
- `codigo/` ‚Äì prompts para gera√ß√£o, revis√£o ou explica√ß√£o de c√≥digo.
- `documentacao/` ‚Äì prompts para gerar ou melhorar documenta√ß√£o t√©cnica.
- `outros/` ‚Äì modelos gen√©ricos ou em rascunho.

---

## üß± Padr√µes e Conven√ß√µes

### üìõ Nome de arquivos

- Usar **kebab-case**:  
  `opiniao-mercado-livre.md`, `resumo-artigo-tecnico.json`
- Nome **descritivo**, refletindo a fun√ß√£o do prompt:
  - `opiniao-mercado-livre.md` ‚Äì gera opini√µes/reviews.
  - `email-followup-cliente.json` ‚Äì gera e-mails de follow-up para clientes.

---

### üìÑ Formato dos arquivos `.md`

Estrutura sugerida:

```markdown
# Nome do Modelo ‚Äì Contexto

## Descri√ß√£o:
Breve descri√ß√£o do objetivo do prompt.

## Prompt:
Texto completo do prompt a ser utilizado com a IA.

## Notas (opcional):

## Observa√ß√µes adicionais.
## Regras espec√≠ficas de uso.
```

#### Exemplo (resumido):


```markdown

# Modelo de Prompt ‚Äì Opini√£o Mercado Livre

## Descri√ß√£o:
Gera opini√µes com base em grau de satisfa√ß√£o e t√≠tulo do produto.

## Prompt:
Crie uma opini√£o de at√© 1500 caracteres sobre um produto que comprei no Mercado Livre. [‚Ä¶]

```
---

### üßæ Formato dos arquivos `.json`

Estrutura sugerida (simples e f√°cil de consumir em c√≥digo):


```json 
{ 
    "name": "Nome curto do modelo", 
    "description": "Descri√ß√£o breve do que o modelo faz.", 
    "prompt": "Texto completo do prompt a ser usado com a IA." 
}
```

#### Exemplo (real):


```json 
{ 
    "name": "Opini√£o Mercado Livre", 
    "description": "Gera opini√µes com base em grau de satisfa√ß√£o e t√≠tulo do produto.", 
    "prompt": "Crie uma opini√£o de at√© 1500 caracteres sobre um produto que comprei no Mercado Livre. O texto deve ter um tom simples, direto e leigo, como se fosse uma avalia√ß√£o espont√¢nea de um consumidor comum. Para cada produto, vou te informar: - Um grau de satisfa√ß√£o (de 1 a 5, onde 1 significa que n√£o recomendo e 5 significa que gostei e recomendo); - O t√≠tulo do an√∫ncio ou nome do produto; - (Opcional) Uma observa√ß√£o que quero que seja inclu√≠da na opini√£o. Na resposta, quero apenas o texto da opini√£o, sem explica√ß√µes ou formata√ß√µes extras. Depois da sua resposta, posso pedir uma nova opini√£o para outro produto ou solicitar que refa√ßa a anterior." 
}
```

---

## üß™ Exemplos de Uso

Abaixo alguns exemplos pr√°ticos de como consumir os arquivos `.json` deste reposit√≥rio em diferentes stacks.
¬¥
> ‚ö†Ô∏è Nos exemplos com APIs de IA, o c√≥digo √© ilustrativo. Adapte para o provedor/modelo que estiver usando (OpenAI, Anthropic, etc.).

---

### üü¶ 1. Uso com Node.js (JavaScript)

#### 1.1. Carregar e usar um prompt localmente

- Instala√ß√£o b√°sica:


```bash
npm init -y npm install fs
```

- Exemplo:


```js 
// scripts/usarPrompt.js 
import fs from "fs"; import path from "path";

const promptPath = path.join( process.cwd(), "mercado-livre", "opiniao-mercado-livre.json" );

const raw = fs.readFileSync(promptPath, "utf-8"); const promptData = JSON.parse(raw);

const promptBase = promptData.prompt;

// Exemplo de dados din√¢micos 
const grauSatisfacao = 5; 
const tituloProduto = "Fone de Ouvido Bluetooth XYZ"; 
const observacao = "A bateria dura bastante e √© confort√°vel para usar por horas.";

const entradaUsuario = 
GrauDeSatisfacao: ${grauSatisfacao}
Produto: ${tituloProduto}
Observa√ß√£o: ${observacao}
;

// Aqui voc√™ concatenaria com o prompt base antes de enviar para a IA 
const mensagemFinal = ${promptBase}\n\n${entradaUsuario};

console.log("Mensagem final a ser enviada para a IA:\n"); 
console.log(mensagemFinal);
```

---

#### 1.2. Exemplo com API (OpenAI via SDK ‚Äì simplificado)


```bash 
npm install openai dotenv
```



```js 
// scripts/usarComOpenAI.js 
import fs from "fs"; 
import path from "path"; 
import OpenAI from "openai"; 
import dotenv from "dotenv";

dotenv.config();

const client = new OpenAI({ apiKey: process.env.OPENAI_API_KEY });

async function main() { const promptPath = path.join( process.cwd(), "mercado-livre", "opiniao-mercado-livre.json" );

const promptData = JSON.parse(fs.readFileSync(promptPath, "utf-8"));

const grauSatisfacao = 4; const tituloProduto = "Mouse sem fio ergon√¥mico ABC"; const observacao = "Uso para trabalho o dia inteiro.";

const entradaUsuario = 
Grau de satisfa√ß√£o: ${grauSatisfacao}
Produto: ${tituloProduto}
Observa√ß√£o: ${observacao}
;

const systemPrompt = promptData.prompt;

const completion = await client.chat.completions.create({ model: "gpt-4o-mini", messages: [ { role: "system", content: systemPrompt }, { role: "user", content: entradaUsuario } ] });

console.log("Opini√£o gerada:"); console.log(completion.choices[0].message.content); }

main().catch(console.error);
```

---

### ‚ö´ 2. Uso com Next.js (App Router)

Exemplo de API route em Next.js 13+ usando o prompt JSON.


```bash
npm install openai dotenv
```



```ts 
// app/api/opiniao-mercado-livre/route.ts 
import { NextRequest, NextResponse } from "next/server"; 
import OpenAI from "openai"; 
import fs from "fs"; 
import path from "path";

const client = new OpenAI({ apiKey: process.env.OPENAI_API_KEY });

export async function POST(req: NextRequest) { try { const { grauSatisfacao, tituloProduto, observacao } = await req.json();

const promptPath = path.join(
  process.cwd(),
  "mercado-livre",
  "opiniao-mercado-livre.json"
);

const promptData = JSON.parse(fs.readFileSync(promptPath, "utf-8"));
const systemPrompt = promptData.prompt;

const entradaUsuario = `
Grau de satisfa√ß√£o: ${grauSatisfacao} Produto: ${tituloProduto} Observa√ß√£o: ${observacao || "Nenhuma observa√ß√£o adicional."} `;

const completion = await client.chat.completions.create({
  model: "gpt-4o-mini",
  messages: [
    { role: "system", content: systemPrompt },
    { role: "user", content: entradaUsuario }
  ]
});

const opiniao = completion.choices[0].message.content;

return NextResponse.json({ opiniao }, { status: 200 });


} catch (error) { console.error(error); return NextResponse.json( { error: "Erro ao gerar opini√£o." }, { status: 500 } ); } }
```

Exemplo de chamada dessa API no frontend:


```ts 
// app/page.tsx (Next.js) "use client";

import { useState } from "react";

export default function HomePage() { const [titulo, setTitulo] = useState(""); 
const [grau, setGrau] = useState(5); 
const [obs, setObs] = useState(""); 
const [resultado, setResultado] = useState("");

const gerarOpiniao = async () => { const res = await fetch("/api/opiniao-mercado-livre", { method: "POST", headers: { "Content-Type": "application/json" }, body: JSON.stringify({ grauSatisfacao: grau, tituloProduto: titulo, observacao: obs }) });

const data = await res.json();
setResultado(data.opiniao || "Erro ao gerar opini√£o.");
};

return (

Gerar Opini√£o ‚Äì Mercado Livre

  <div style={{ display: "flex", flexDirection: "column", gap: 8, maxWidth: 400 }}>
    <label>
      T√≠tulo do produto:
      <input
        value={titulo}
        onChange={e => setTitulo(e.target.value)}
        style={{ width: "100%" }}
      />
    </label>

    <label>
      Grau de satisfa√ß√£o (1 a 5):
      <input
        type="number"
        min={1}
        max={5}
        value={grau}
        onChange={e => setGrau(Number(e.target.value))}
      />
    </label>

    <label>
      Observa√ß√£o (opcional):
      <textarea
        value={obs}
        onChange={e => setObs(e.target.value)}
      />
    </label>

    <button onClick={gerarOpiniao}>Gerar opini√£o</button>
  </div>

  <section style={{ marginTop: 24 }}>
    <h2>Opini√£o gerada:</h2>
    <pre>{resultado}</pre>
  </section>
</main>


); 
}
```
---

### üêç 3. Uso com Python

#### 3.1. Carregar o prompt `.json` e montar a mensagem


```bash
pip install openai python-dotenv
```



```python

>> scripts/usar_prompt.py

import json 
import os from pathlib 
import Path from dotenv 
import load_dotenv from openai 
import OpenAI

load_dotenv() client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

BASE_DIR = Path(file).resolve().parent.parent prompt_path = BASE_DIR / "mercado-livre" / "opiniao-mercado-livre.json"

with open(prompt_path, "r", encoding="utf-8") as f: prompt_data = json.load(f)

system_prompt = prompt_data["prompt"]

grau_satisfacao = 3 titulo_produto = "Teclado mec√¢nico ABC" observacao = "Barulho um pouco alto, mas confort√°vel."

entrada_usuario = f""" Grau de satisfa√ß√£o: {grau_satisfacao} Produto: {titulo_produto} Observa√ß√£o: {observacao} """

response = client.chat.completions.create( model="gpt-4o-mini", messages=[ {"role": "system", "content": system_prompt}, {"role": "user", "content": entrada_usuario}, ], )

opiniao = response.choices[0].message.content print("Opini√£o gerada:\n") print(opiniao)
```

---

## ü§ù Contribui√ß√µes

Se o reposit√≥rio estiver aberto a contribui√ß√µes, fluxo sugerido:

1. Fa√ßa um **fork** deste reposit√≥rio.
2. Crie uma nova *branch*:


```bash
git checkout -b feature/novo-modelo-prompt
```
3. Adicione seus arquivos de prompt seguindo os padr√µes:
   - Estrutura de pastas coerente.
   - Nomes em kebab-case.
   - Formatos `.md` e, opcionalmente, `.json`.
4. Fa√ßa *commit* das altera√ß√µes:


```bash
git commit -m "feat: adiciona modelo de prompt para XYZ"
```
5. Envie a *branch*:


```bash 
git push origin feature/novo-modelo-prompt
``` 
6. Abra um **Pull Request** descrevendo:
   - O objetivo do novo modelo.
   - Exemplos de uso (se relevante).

---

## üìú Licen√ßa

Este projeto est√° licenciado sob a **Licen√ßa MIT**.  
Consulte o arquivo [`LICENSE`](./LICENSE) para mais detalhes.